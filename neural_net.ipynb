{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "   Unnamed: 0       tau     tau_F      tau_SG      tau_SR        m0   x0   a0      a_max         n  resolution   type  t_prime  t1max       x_c       a_c       m_c        dt       ptime  mem_stiff  prime_stiff    mem_time  prime_time\n",
      "0           0  0.743858  1.487717  528.375005  278.855753  4.074178  0.2  0.2  39.433618  4.836024         0.5  stiff      0.0    0.0  0.916890  1.065067  1.661773  0.500071  208.217373   3.636884    15.227721    0.500071  208.029656\n",
      "1           1  1.042435  2.084869  212.193700  177.502378  7.308520  0.2  0.2  43.531944  3.196355         0.5  stiff      0.0    0.0  0.816647  1.086740  0.527684  0.500082  474.372130   2.706279     6.296953  225.037042  474.078035\n",
      "2           2  0.795999  1.591999  706.711448  503.692032  7.988656  0.2  0.2  98.490928  4.558613         0.5  stiff      0.0    0.0  0.906801  1.050135  1.306791  0.500118  137.667567   7.396257    15.742482    0.500118  137.032246\n",
      "3           3  0.824328  1.648655  274.754759  103.088087  5.238385  0.2  0.2  14.886602  3.262077         0.5  stiff      0.0    0.0  0.823499  1.352037  0.755473  0.500051  463.041979   2.524053     7.056124  103.510611  463.047467\n",
      "4           4  0.819784  1.639567  748.708609  175.565873  6.997904  0.2  0.2  61.135164  3.448168         0.5  stiff      0.0    0.0  0.840987  1.299319  0.831517  0.500142  137.912304   2.281369    12.457698    0.000000  137.039005\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from mm_NN import *\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "pd.set_option('display.expand_frame_repr', False, 'display.max_columns', None)\n",
    "\n",
    "direc = './stiff_results/'\n",
    "fname = 'static_LHS_SG_SR_ng'\n",
    "\n",
    "dataDF = pd.read_csv(direc + fname +'.csv')\n",
    "input_profs = np.load(direc + fname + '_inputs.npy', allow_pickle=True)\n",
    "\n",
    "print(dataDF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### figure 3 3D landscapes\n",
    "\n",
    "# stiff genes\n",
    "res = 500\n",
    "m0 = 1.\n",
    "tau = 1.\n",
    "n = 4\n",
    "\n",
    "x_c = x_crit(n)\n",
    "a_c = alpha_crit(n, tau)\n",
    "m_c = m_crit_over_m0(n, tau)\n",
    "\n",
    "params = {}\n",
    "\n",
    "choose_m = 0.9\n",
    "# have been using 0.4 and 0.6\n",
    "params['x_c'] = x_c; params['a_c'] = a_c; params['type'] = 'stiff'; params['m0'] = m0; \n",
    "params['tau'] = tau; params['n'] = n\n",
    "m_c = scipy.optimize.fsolve(m_crit_general, 0.5, args=(params), xtol=1e-10)[0] / params['m0']\n",
    "# choose_mc_ind = np.where(np.abs(m_space - choose_mc) == np.amin(np.abs(m_space-choose_mc)))[0]\n",
    "\n",
    "params['m_c'] = m_c\n",
    "\n",
    "choose_m = m_c\n",
    "\n",
    "x_space = np.linspace(0, 1.75, res)\n",
    "a_space = np.linspace(0.2, 2., res)\n",
    "# x_stiff = 1-np.exp(-choose_m/m0)\n",
    "\n",
    "ac_ind = np.where(np.abs(a_space - a_c) == np.amin(np.abs(a_space-a_c)))[0]\n",
    "# print(ac_ind)\n",
    "\n",
    "U_data = np.zeros((len(x_space), len(a_space)))\n",
    "\n",
    "for ai, aa in enumerate(a_space):\n",
    "    for xi, xx in enumerate(x_space):\n",
    "        U_data[xi, ai] = U(f_m, choose_m, xx, aa, params)\n",
    "\n",
    "\n",
    "print(np.shape(np.abs(np.diff(U_data, axis=0))))\n",
    "\n",
    "ind_below = int(ac_ind - res/10)\n",
    "ind_above = int(ac_ind + res/10)\n",
    "\n",
    "m0coords = []\n",
    "m1coords = []\n",
    "m2coords = []\n",
    "for ai, aa in enumerate(a_space):\n",
    "#     xargs = argrelextrema(np.abs(np.diff(U_data[:,ai])), np.less)[0]\n",
    "    xargs = find_peaks(-np.abs(np.diff(U_data[:,ai])))[0]\n",
    "    if aa > a_c:\n",
    "#         xargs = argrelextrema(np.diff(U_data[:,ai], n=2), np.greater)[0]\n",
    "#         print(np.diff(U_data[:,ai], n=2))\n",
    "#         if ai == ind_above:\n",
    "#             fig3, ax3 = plt.subplots(2,1, figsize=(6,6))\n",
    "#             # np.diff(U_data[:,ai], n=1)[0]\n",
    "#             ax3[0].plot(x_space, np.insert(np.diff(U_data[:,ai], n=1),0,[np.diff(U_data[:,ai], n=1)[0]]))\n",
    "#             ax3[1].plot(x_space, U_data[:,ai])\n",
    "#             sys.exit()\n",
    "        x_mins = x_space[xargs]\n",
    "        if len(x_mins) > 1:\n",
    "            m1coords.append([np.amin(x_mins), aa, U_data[np.amin(xargs), ai]])\n",
    "            m2coords.append([np.amax(x_mins),aa, U_data[np.amax(xargs), ai]])\n",
    "        else:\n",
    "#             print(x_mins)\n",
    "            if np.abs(np.amin(x_mins) - m1coords[-1][0]) < np.abs(np.amin(x_mins) - m2coords[-1][0]):\n",
    "                m1coords.append([np.amin(x_mins), aa, U_data[np.amin(xargs), ai]])\n",
    "            else:\n",
    "                m2coords.append([np.amax(x_mins),aa, U_data[np.amax(xargs), ai]])\n",
    "    else:\n",
    "#         xargs = argrelextrema(np.abs(np.diff(U_data[:,ai])), np.less)[0]\n",
    "        x_mins = x_space[xargs]\n",
    "        m0coords.append([np.amin(x_mins),aa, U_data[np.amin(xargs), ai]])\n",
    "\n",
    "m0coords = np.array(m0coords)\n",
    "m1coords = np.array(m1coords)\n",
    "m2coords = np.array(m2coords)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
